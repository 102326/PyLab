# PyLabFastAPI/app/core/agent.py
import logging
from typing import AsyncGenerator, List, Dict, Any
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver
from app.utils.llm_factory import LLMFactory
from app.models.user import User
from app.tools.user import get_user_tools

logger = logging.getLogger(__name__)


class PyLabAgent:
    """
    PyLab ä¸šåŠ¡æ™ºèƒ½ä½“ (åŸºäº LangGraph v1.0.5+)
    """

    def __init__(self, user: User):
        self.user = user
        self.thread_id = str(user.id)  # ä½¿ç”¨ç”¨æˆ·IDä½œä¸ºçº¿ç¨‹ID

        # 1. è·å– LLM
        self.llm = LLMFactory.get_llm(temperature=0.3)

        # 2. è·å–å·¥å…·é“¾
        self.tools = get_user_tools(user)

        # 3. æ„å»º System Prompt
        self.system_prompt = (
            f"ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ç¼–ç¨‹æ•™è‚²åŠ©æ‰‹ PyLab AIã€‚å½“å‰å¯¹è¯çš„ç”¨æˆ·æ˜¯ {self.user.nickname} (ID: {self.user.role})ã€‚"
            "è¯·é»˜è®¤ä½¿ç”¨ä¸­æ–‡å›ç­”ã€‚"
            "ä½ å¯ä»¥ä½¿ç”¨å·¥å…·æŸ¥è¯¢æ•°æ®ï¼Œä½†ä¸¥ç¦ç¼–é€ ç”¨æˆ·ä¿¡æ¯ã€‚"
            "å¦‚æœç”¨æˆ·è¯¢é—®ä¸ç¼–ç¨‹ã€è¯¾ç¨‹æ— å…³çš„é—®é¢˜ï¼Œè¯·ç¤¼è²Œæ‹’ç»ã€‚"
        )

        # 4. åˆ›å»º Graph
        # ã€æ ¸å¿ƒä¿®å¤ã€‘å°† state_modifier æ”¹ä¸º prompt
        self.graph = create_react_agent(
            model=self.llm,
            tools=self.tools,
            prompt=self.system_prompt,  # ğŸ‘ˆ è¿™é‡Œæ”¹æˆäº† prompt
            checkpointer=MemorySaver()
        )

    async def astream_chat(self, user_input: str, history: List[dict] = None) -> AsyncGenerator[str, None]:
        """
        æµå¼å¯¹è¯æ¥å£
        """
        config = {"configurable": {"thread_id": self.thread_id}}

        # LangGraph ä¼šè‡ªåŠ¨ç®¡ç†å†å²ï¼Œè¿™é‡Œåªä¼ æœ€æ–°æ¶ˆæ¯
        inputs = {"messages": [HumanMessage(content=user_input)]}

        try:
            # v2 ç‰ˆæœ¬æµå¼è¾“å‡º
            async for event in self.graph.astream_events(inputs, config=config, version="v2"):
                kind = event["event"]

                # è¿‡æ»¤å‡º LLM ç”Ÿæˆçš„æ–‡æœ¬å—
                if kind == "on_chat_model_stream":
                    content = event["data"]["chunk"].content
                    if content:
                        yield content

        except Exception as e:
            logger.error(f"Agent Error: {e}")
            # å‘ç”Ÿé”™è¯¯æ—¶ï¼Œè¿”å›å‹å¥½çš„æç¤ºï¼ˆè¿™åœ¨æµå¼æ¥å£ä¸­å¾ˆé‡è¦ï¼Œé˜²æ­¢å‰ç«¯æ–­è¿ï¼‰
            yield f"âš ï¸ æŠ±æ­‰ï¼ŒAI é‡åˆ°äº†ä¸€ç‚¹å°é—®é¢˜: {str(e)}"